{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ec31566-36cf-4fb6-92f2-9aed52b17eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mfaishaldp\\anaconda3\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mfaishaldp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mfaishaldp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "import gensim\n",
    "from gensim.models import FastText\n",
    "import pandas as pd\n",
    "\n",
    "# LIBRARY UNTUK MENGOLAH DATA\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# LIBRARY UNTUK PREPROCESSING\n",
    "import nltk #import library nltk\n",
    "from nltk.tokenize import word_tokenize #import word_tokenize for tokenizing text into words \n",
    "from nltk.tokenize import sent_tokenize #import sent_tokenize for tokenizing paragraph into sentences\n",
    "from nltk.stem.porter import PorterStemmer #import Porter Stemmer Algorithm \n",
    "from nltk.stem import WordNetLemmatizer #import WordNet lemmatizer \n",
    "from nltk.corpus import stopwords #import stopwords\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory #import Indonesian Stemmer\n",
    "import re,string #import regular expression\n",
    "\n",
    "# STOPWORD DENGAN SASTRAWI\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "\n",
    "# TOKENIZE\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80d6f7ee-c1a2-4065-8d5f-a59d75251dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "dta = pd.read_csv('new_Data - Bismillah - Stemming.csv')\n",
    "dtf = dta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85002765-031e-49ee-b726-5ceaeb628887",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtf.drop_duplicates(subset='Stemming', inplace = True)\n",
    "dtf.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48902150-007a-4497-b3fe-1ce501ac8310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cekDup = dtf.duplicated(subset = 'Stemming')\n",
    "cekDup.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5518581c-007c-4ab8-b7a3-a7dfebd90b98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date            0\n",
       "Text            0\n",
       "Label           0\n",
       "Text Clean      1\n",
       "meaningless     1\n",
       "Case Folding    1\n",
       "normalisasi     1\n",
       "Stopword        1\n",
       "Stemming        1\n",
       "tokenizing      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtf.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "317d85f5-ee95-433c-b620-d6f212415885",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtf.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b56242d9-5fd6-49e8-b4c3-c36db16d5101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    7769\n",
       " 1    6940\n",
       " 0    5648\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtf['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1dcb8d5a-9d32-432c-b882-ffa0ac3c45bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtf.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4cca04-7f38-4773-b3e7-1588bd27da76",
   "metadata": {},
   "source": [
    "## Data Actual Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5dc62767-2a6d-4627-b05f-ee35d3ccf499",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizing(data):\n",
    "    return nltk.tokenize.word_tokenize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "258d3dab-1b3f-4c5b-9fb5-859e280f5ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_actual = dtf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db01e58e-d599-4f9e-8816-dcc600cb23d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_actual = FastText(sentences = df_actual['tokenizing'], window = 5, min_count = 3, workers = 4, sg = 0, hs = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7bfca5f5-f913-427c-bdeb-550c1bce74f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_actual.save('modelft-26jan-Dataactual')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcf984c-980b-422f-bf80-296536873e8f",
   "metadata": {},
   "source": [
    "## DATA ACTUAL + PRETRAINED FASTTEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c6ea021-e51c-4382-a616-a1d29594ab7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc_actual = dtf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72a5949a-a401-484a-a37a-279006b3235b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Date</th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>Text Clean</th>\n",
       "      <th>meaningless</th>\n",
       "      <th>Case Folding</th>\n",
       "      <th>normalisasi</th>\n",
       "      <th>Stopword</th>\n",
       "      <th>Stemming</th>\n",
       "      <th>tokenizing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-07-20</td>\n",
       "      <td>Bagaimana ini gk ada pemberitahuan kpn selesai...</td>\n",
       "      <td>-1</td>\n",
       "      <td>Bagaimana ini gk ada pemberitahuan kpn selesai...</td>\n",
       "      <td>Bagaimana   gk ada pemberitahuan kpn selesainy...</td>\n",
       "      <td>bagaimana ini gk ada pemberitahuan kpn selesai...</td>\n",
       "      <td>bagaimana ini tidak ada pemberitahuan kapan se...</td>\n",
       "      <td>bagaimana ini tidak ada pemberitahuan kapan se...</td>\n",
       "      <td>bagaimana ini tidak ada pemberitahuan kapan se...</td>\n",
       "      <td>['bagaimana', 'ini', 'tidak', 'ada', 'pemberit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-07-20</td>\n",
       "      <td>HOREEE. awal saldo nol. Setelah cek 175jt. gue...</td>\n",
       "      <td>0</td>\n",
       "      <td>HOREE awal saldo nol Setelah cek jt gue tarik ...</td>\n",
       "      <td>HOREE awal saldo nol Setelah cek jt gue tarik ...</td>\n",
       "      <td>horee awal saldo nol setelah cek jt gue tarik ...</td>\n",
       "      <td>hore awal saldo nol setelah cek juta saya tari...</td>\n",
       "      <td>hore awal saldo nol setelah cek juta saya tari...</td>\n",
       "      <td>hore awal saldo nol telah cek juta saya tarik ...</td>\n",
       "      <td>['hore', 'awal', 'saldo', 'nol', 'telah', 'cek...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-07-20</td>\n",
       "      <td>Bankerot nih namanya</td>\n",
       "      <td>-1</td>\n",
       "      <td>Bankerot nih namanya</td>\n",
       "      <td>Bankerot nih namanya</td>\n",
       "      <td>bankerot nih namanya</td>\n",
       "      <td>bangkrut ini namanya</td>\n",
       "      <td>bangkrut ini namanya</td>\n",
       "      <td>bangkrut ini nama</td>\n",
       "      <td>['bangkrut', 'ini', 'nama']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2019-07-20</td>\n",
       "      <td>Alhandulillah . . . .Rek Mandiri saya amaannn ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Alhandulillah Rek Mandiri saya amaann masih se...</td>\n",
       "      <td>Alhandulillah Rek Mandiri   amaann       kemarin</td>\n",
       "      <td>alhandulillah rek mandiri saya amaann masih se...</td>\n",
       "      <td>alhamdulillah rekening mandiri saya aman masih...</td>\n",
       "      <td>alhamdulillah rekening mandiri saya aman masih...</td>\n",
       "      <td>alhamdulillah rekening mandiri saya aman masih...</td>\n",
       "      <td>['alhamdulillah', 'rekening', 'mandiri', 'saya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2019-07-20</td>\n",
       "      <td>mohon infonya kapan mandiri bisa normal lagi u...</td>\n",
       "      <td>0</td>\n",
       "      <td>mohon infonya kapan mandiri bisa normal lagi u...</td>\n",
       "      <td>mohon infonya kapan mandiri   normal lagi urus...</td>\n",
       "      <td>mohon infonya kapan mandiri bisa normal lagi u...</td>\n",
       "      <td>mohon infonya kapan mandiri bisa normal lagi u...</td>\n",
       "      <td>mohon infonya kapan mandiri bisa normal lagi u...</td>\n",
       "      <td>mohon info kapan mandiri bisa normal lagi urus...</td>\n",
       "      <td>['mohon', 'info', 'kapan', 'mandiri', 'bisa', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20352</th>\n",
       "      <td>20353</td>\n",
       "      <td>2019-04-02</td>\n",
       "      <td>@GdeDyaksa Terima kasih Bpk Dyaksa atas partis...</td>\n",
       "      <td>1</td>\n",
       "      <td>Terima kasih Bpk Dyaksa atas partisipasi yg di...</td>\n",
       "      <td>Terima kasih Bpk Dyaksa atas partisipasi   dib...</td>\n",
       "      <td>terima kasih bpk dyaksa atas partisipasi yg di...</td>\n",
       "      <td>terima kasih bapak dyaksa atas partisipasi yan...</td>\n",
       "      <td>terima kasih bapak dyaksa atas partisipasi yan...</td>\n",
       "      <td>terima kasih bapak dyaksa atas partisipasi yan...</td>\n",
       "      <td>['terima', 'kasih', 'bapak', 'dyaksa', 'atas',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20353</th>\n",
       "      <td>20354</td>\n",
       "      <td>2019-04-02</td>\n",
       "      <td>@mohammadiball Terima kasih Bpk Ibal atas part...</td>\n",
       "      <td>1</td>\n",
       "      <td>Terima kasih Bpk Ibal atas partisipasi yg dibe...</td>\n",
       "      <td>Terima kasih Bpk Ibal atas partisipasi   diber...</td>\n",
       "      <td>terima kasih bpk ibal atas partisipasi yg dibe...</td>\n",
       "      <td>terima kasih bapak ibal atas partisipasi yang ...</td>\n",
       "      <td>terima kasih bapak ibal atas partisipasi yang ...</td>\n",
       "      <td>terima kasih bapak ibal atas partisipasi yang ...</td>\n",
       "      <td>['terima', 'kasih', 'bapak', 'ibal', 'atas', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20354</th>\n",
       "      <td>20355</td>\n",
       "      <td>2019-04-02</td>\n",
       "      <td>@JuraganHusin Terima kasih Bpk Husin atas part...</td>\n",
       "      <td>1</td>\n",
       "      <td>Terima kasih Bpk Husin atas partisipasi yg dib...</td>\n",
       "      <td>Terima kasih Bpk Husin atas partisipasi   dibe...</td>\n",
       "      <td>terima kasih bpk husin atas partisipasi yg dib...</td>\n",
       "      <td>terima kasih bapak husin atas partisipasi yang...</td>\n",
       "      <td>terima kasih bapak husin atas partisipasi yang...</td>\n",
       "      <td>terima kasih bapak husin atas partisipasi yang...</td>\n",
       "      <td>['terima', 'kasih', 'bapak', 'husin', 'atas', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20355</th>\n",
       "      <td>20356</td>\n",
       "      <td>2019-04-02</td>\n",
       "      <td>@vill4nk Terima kasih Bpk/Ibu atas partisipasi...</td>\n",
       "      <td>1</td>\n",
       "      <td>nk Terima kasih Bpk Ibu atas partisipasi yg di...</td>\n",
       "      <td>nk Terima kasih Bpk Ibu atas partisipasi   dib...</td>\n",
       "      <td>nk terima kasih bpk ibu atas partisipasi yg di...</td>\n",
       "      <td>natural killer terima kasih bapak ibu atas par...</td>\n",
       "      <td>natural killer terima kasih bapak ibu atas par...</td>\n",
       "      <td>natural killer terima kasih bapak ibu atas par...</td>\n",
       "      <td>['natural', 'killer', 'terima', 'kasih', 'bapa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20356</th>\n",
       "      <td>20357</td>\n",
       "      <td>2019-04-02</td>\n",
       "      <td>@sofian_dm Terima kasih Bpk Sofian atas partis...</td>\n",
       "      <td>1</td>\n",
       "      <td>dm Terima kasih Bpk Sofian atas partisipasi yg...</td>\n",
       "      <td>dm Terima kasih Bpk Sofian atas partisipasi   ...</td>\n",
       "      <td>dm terima kasih bpk sofian atas partisipasi yg...</td>\n",
       "      <td>direct message terima kasih bapak sofian atas ...</td>\n",
       "      <td>direct message terima kasih bapak sofian atas ...</td>\n",
       "      <td>direct message terima kasih bapak sofian atas ...</td>\n",
       "      <td>['direct', 'message', 'terima', 'kasih', 'bapa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20357 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index        Date                                               Text  \\\n",
       "0          0  2019-07-20  Bagaimana ini gk ada pemberitahuan kpn selesai...   \n",
       "1          1  2019-07-20  HOREEE. awal saldo nol. Setelah cek 175jt. gue...   \n",
       "2          2  2019-07-20                               Bankerot nih namanya   \n",
       "3          3  2019-07-20  Alhandulillah . . . .Rek Mandiri saya amaannn ...   \n",
       "4          4  2019-07-20  mohon infonya kapan mandiri bisa normal lagi u...   \n",
       "...      ...         ...                                                ...   \n",
       "20352  20353  2019-04-02  @GdeDyaksa Terima kasih Bpk Dyaksa atas partis...   \n",
       "20353  20354  2019-04-02  @mohammadiball Terima kasih Bpk Ibal atas part...   \n",
       "20354  20355  2019-04-02  @JuraganHusin Terima kasih Bpk Husin atas part...   \n",
       "20355  20356  2019-04-02  @vill4nk Terima kasih Bpk/Ibu atas partisipasi...   \n",
       "20356  20357  2019-04-02  @sofian_dm Terima kasih Bpk Sofian atas partis...   \n",
       "\n",
       "       Label                                         Text Clean  \\\n",
       "0         -1  Bagaimana ini gk ada pemberitahuan kpn selesai...   \n",
       "1          0  HOREE awal saldo nol Setelah cek jt gue tarik ...   \n",
       "2         -1                               Bankerot nih namanya   \n",
       "3          1  Alhandulillah Rek Mandiri saya amaann masih se...   \n",
       "4          0  mohon infonya kapan mandiri bisa normal lagi u...   \n",
       "...      ...                                                ...   \n",
       "20352      1  Terima kasih Bpk Dyaksa atas partisipasi yg di...   \n",
       "20353      1  Terima kasih Bpk Ibal atas partisipasi yg dibe...   \n",
       "20354      1  Terima kasih Bpk Husin atas partisipasi yg dib...   \n",
       "20355      1  nk Terima kasih Bpk Ibu atas partisipasi yg di...   \n",
       "20356      1  dm Terima kasih Bpk Sofian atas partisipasi yg...   \n",
       "\n",
       "                                             meaningless  \\\n",
       "0      Bagaimana   gk ada pemberitahuan kpn selesainy...   \n",
       "1      HOREE awal saldo nol Setelah cek jt gue tarik ...   \n",
       "2                                   Bankerot nih namanya   \n",
       "3       Alhandulillah Rek Mandiri   amaann       kemarin   \n",
       "4      mohon infonya kapan mandiri   normal lagi urus...   \n",
       "...                                                  ...   \n",
       "20352  Terima kasih Bpk Dyaksa atas partisipasi   dib...   \n",
       "20353  Terima kasih Bpk Ibal atas partisipasi   diber...   \n",
       "20354  Terima kasih Bpk Husin atas partisipasi   dibe...   \n",
       "20355  nk Terima kasih Bpk Ibu atas partisipasi   dib...   \n",
       "20356  dm Terima kasih Bpk Sofian atas partisipasi   ...   \n",
       "\n",
       "                                            Case Folding  \\\n",
       "0      bagaimana ini gk ada pemberitahuan kpn selesai...   \n",
       "1      horee awal saldo nol setelah cek jt gue tarik ...   \n",
       "2                                   bankerot nih namanya   \n",
       "3      alhandulillah rek mandiri saya amaann masih se...   \n",
       "4      mohon infonya kapan mandiri bisa normal lagi u...   \n",
       "...                                                  ...   \n",
       "20352  terima kasih bpk dyaksa atas partisipasi yg di...   \n",
       "20353  terima kasih bpk ibal atas partisipasi yg dibe...   \n",
       "20354  terima kasih bpk husin atas partisipasi yg dib...   \n",
       "20355  nk terima kasih bpk ibu atas partisipasi yg di...   \n",
       "20356  dm terima kasih bpk sofian atas partisipasi yg...   \n",
       "\n",
       "                                             normalisasi  \\\n",
       "0      bagaimana ini tidak ada pemberitahuan kapan se...   \n",
       "1      hore awal saldo nol setelah cek juta saya tari...   \n",
       "2                                   bangkrut ini namanya   \n",
       "3      alhamdulillah rekening mandiri saya aman masih...   \n",
       "4      mohon infonya kapan mandiri bisa normal lagi u...   \n",
       "...                                                  ...   \n",
       "20352  terima kasih bapak dyaksa atas partisipasi yan...   \n",
       "20353  terima kasih bapak ibal atas partisipasi yang ...   \n",
       "20354  terima kasih bapak husin atas partisipasi yang...   \n",
       "20355  natural killer terima kasih bapak ibu atas par...   \n",
       "20356  direct message terima kasih bapak sofian atas ...   \n",
       "\n",
       "                                                Stopword  \\\n",
       "0      bagaimana ini tidak ada pemberitahuan kapan se...   \n",
       "1      hore awal saldo nol setelah cek juta saya tari...   \n",
       "2                                   bangkrut ini namanya   \n",
       "3      alhamdulillah rekening mandiri saya aman masih...   \n",
       "4      mohon infonya kapan mandiri bisa normal lagi u...   \n",
       "...                                                  ...   \n",
       "20352  terima kasih bapak dyaksa atas partisipasi yan...   \n",
       "20353  terima kasih bapak ibal atas partisipasi yang ...   \n",
       "20354  terima kasih bapak husin atas partisipasi yang...   \n",
       "20355  natural killer terima kasih bapak ibu atas par...   \n",
       "20356  direct message terima kasih bapak sofian atas ...   \n",
       "\n",
       "                                                Stemming  \\\n",
       "0      bagaimana ini tidak ada pemberitahuan kapan se...   \n",
       "1      hore awal saldo nol telah cek juta saya tarik ...   \n",
       "2                                      bangkrut ini nama   \n",
       "3      alhamdulillah rekening mandiri saya aman masih...   \n",
       "4      mohon info kapan mandiri bisa normal lagi urus...   \n",
       "...                                                  ...   \n",
       "20352  terima kasih bapak dyaksa atas partisipasi yan...   \n",
       "20353  terima kasih bapak ibal atas partisipasi yang ...   \n",
       "20354  terima kasih bapak husin atas partisipasi yang...   \n",
       "20355  natural killer terima kasih bapak ibu atas par...   \n",
       "20356  direct message terima kasih bapak sofian atas ...   \n",
       "\n",
       "                                              tokenizing  \n",
       "0      ['bagaimana', 'ini', 'tidak', 'ada', 'pemberit...  \n",
       "1      ['hore', 'awal', 'saldo', 'nol', 'telah', 'cek...  \n",
       "2                            ['bangkrut', 'ini', 'nama']  \n",
       "3      ['alhamdulillah', 'rekening', 'mandiri', 'saya...  \n",
       "4      ['mohon', 'info', 'kapan', 'mandiri', 'bisa', ...  \n",
       "...                                                  ...  \n",
       "20352  ['terima', 'kasih', 'bapak', 'dyaksa', 'atas',...  \n",
       "20353  ['terima', 'kasih', 'bapak', 'ibal', 'atas', '...  \n",
       "20354  ['terima', 'kasih', 'bapak', 'husin', 'atas', ...  \n",
       "20355  ['natural', 'killer', 'terima', 'kasih', 'bapa...  \n",
       "20356  ['direct', 'message', 'terima', 'kasih', 'bapa...  \n",
       "\n",
       "[20357 rows x 11 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfc_actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98de328e-c9a7-43e1-a3e1-5ebe2956ecb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "lst_c = []\n",
    "\n",
    "for i in range(len(dfc_actual['tokenizing'])):\n",
    "    lst_c.append(ast.literal_eval(dfc_actual['tokenizing'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3df7e19a-41c5-41fb-afac-099121cff1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath\n",
    "model_gab_actualpretrained = FastText.load_fasttext_format(\"cc.id.300.bin.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "45b960e6-012f-45aa-897f-1e99399fae47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(341278, 1966085)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gab_actualpretrained.build_vocab(lst_c, update=True)\n",
    "model_gab_actualpretrained.train(lst_c, total_examples = len(lst_c), epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2164db6-0ca6-4a4c-a937-c4d46b525490",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gab_actualpretrained.save('modelft-26jan-actualpretrained')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
