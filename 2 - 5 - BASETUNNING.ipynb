{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6358af3d-bf36-4798-b1eb-67da0e710109",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mfaishaldp\\anaconda3\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# LIBRARY UNTUK PREPROCESSING\n",
    "import nltk #import library nltk\n",
    "from nltk.tokenize import word_tokenize #import word_tokenize for tokenizing text into words \n",
    "from nltk.tokenize import sent_tokenize #import sent_tokenize for tokenizing paragraph into sentences\n",
    "from nltk.stem.porter import PorterStemmer #import Porter Stemmer Algorithm \n",
    "from nltk.stem import WordNetLemmatizer #import WordNet lemmatizer \n",
    "from nltk.corpus import stopwords #import stopwords\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory #import Indonesian Stemmer\n",
    "import re,string #import regular expression\n",
    "\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "from tqdm import tqdm\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a48ba7ae-1c27-4d70-8786-cf1343dddcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0be9459-8302-4533-b126-178553cef6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "dta = pd.read_csv('new_Data - Bismillah - Stemming.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "386b6569-25dd-4e84-aa12-cec75c169db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtf = dta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32d90bda-6010-4bb5-8fb9-d803e249e01b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>Text Clean</th>\n",
       "      <th>meaningless</th>\n",
       "      <th>Case Folding</th>\n",
       "      <th>normalisasi</th>\n",
       "      <th>Stopword</th>\n",
       "      <th>Stemming</th>\n",
       "      <th>tokenizing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-07-20</td>\n",
       "      <td>Bagaimana ini gk ada pemberitahuan kpn selesai...</td>\n",
       "      <td>-1</td>\n",
       "      <td>Bagaimana ini gk ada pemberitahuan kpn selesai...</td>\n",
       "      <td>Bagaimana   gk ada pemberitahuan kpn selesainy...</td>\n",
       "      <td>bagaimana ini gk ada pemberitahuan kpn selesai...</td>\n",
       "      <td>bagaimana ini tidak ada pemberitahuan kapan se...</td>\n",
       "      <td>bagaimana ini tidak ada pemberitahuan kapan se...</td>\n",
       "      <td>bagaimana ini tidak ada pemberitahuan kapan se...</td>\n",
       "      <td>['bagaimana', 'ini', 'tidak', 'ada', 'pemberit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-07-20</td>\n",
       "      <td>HOREEE. awal saldo nol. Setelah cek 175jt. gue...</td>\n",
       "      <td>0</td>\n",
       "      <td>HOREE awal saldo nol Setelah cek jt gue tarik ...</td>\n",
       "      <td>HOREE awal saldo nol Setelah cek jt gue tarik ...</td>\n",
       "      <td>horee awal saldo nol setelah cek jt gue tarik ...</td>\n",
       "      <td>hore awal saldo nol setelah cek juta saya tari...</td>\n",
       "      <td>hore awal saldo nol setelah cek juta saya tari...</td>\n",
       "      <td>hore awal saldo nol telah cek juta saya tarik ...</td>\n",
       "      <td>['hore', 'awal', 'saldo', 'nol', 'telah', 'cek...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-07-20</td>\n",
       "      <td>Bankerot nih namanya</td>\n",
       "      <td>-1</td>\n",
       "      <td>Bankerot nih namanya</td>\n",
       "      <td>Bankerot nih namanya</td>\n",
       "      <td>bankerot nih namanya</td>\n",
       "      <td>bangkrut ini namanya</td>\n",
       "      <td>bangkrut ini namanya</td>\n",
       "      <td>bangkrut ini nama</td>\n",
       "      <td>['bangkrut', 'ini', 'nama']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-07-20</td>\n",
       "      <td>Alhandulillah . . . .Rek Mandiri saya amaannn ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Alhandulillah Rek Mandiri saya amaann masih se...</td>\n",
       "      <td>Alhandulillah Rek Mandiri   amaann       kemarin</td>\n",
       "      <td>alhandulillah rek mandiri saya amaann masih se...</td>\n",
       "      <td>alhamdulillah rekening mandiri saya aman masih...</td>\n",
       "      <td>alhamdulillah rekening mandiri saya aman masih...</td>\n",
       "      <td>alhamdulillah rekening mandiri saya aman masih...</td>\n",
       "      <td>['alhamdulillah', 'rekening', 'mandiri', 'saya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-07-20</td>\n",
       "      <td>mohon infonya kapan mandiri bisa normal lagi u...</td>\n",
       "      <td>0</td>\n",
       "      <td>mohon infonya kapan mandiri bisa normal lagi u...</td>\n",
       "      <td>mohon infonya kapan mandiri   normal lagi urus...</td>\n",
       "      <td>mohon infonya kapan mandiri bisa normal lagi u...</td>\n",
       "      <td>mohon infonya kapan mandiri bisa normal lagi u...</td>\n",
       "      <td>mohon infonya kapan mandiri bisa normal lagi u...</td>\n",
       "      <td>mohon info kapan mandiri bisa normal lagi urus...</td>\n",
       "      <td>['mohon', 'info', 'kapan', 'mandiri', 'bisa', ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date                                               Text  Label  \\\n",
       "0  2019-07-20  Bagaimana ini gk ada pemberitahuan kpn selesai...     -1   \n",
       "1  2019-07-20  HOREEE. awal saldo nol. Setelah cek 175jt. gue...      0   \n",
       "2  2019-07-20                               Bankerot nih namanya     -1   \n",
       "3  2019-07-20  Alhandulillah . . . .Rek Mandiri saya amaannn ...      1   \n",
       "4  2019-07-20  mohon infonya kapan mandiri bisa normal lagi u...      0   \n",
       "\n",
       "                                          Text Clean  \\\n",
       "0  Bagaimana ini gk ada pemberitahuan kpn selesai...   \n",
       "1  HOREE awal saldo nol Setelah cek jt gue tarik ...   \n",
       "2                               Bankerot nih namanya   \n",
       "3  Alhandulillah Rek Mandiri saya amaann masih se...   \n",
       "4  mohon infonya kapan mandiri bisa normal lagi u...   \n",
       "\n",
       "                                         meaningless  \\\n",
       "0  Bagaimana   gk ada pemberitahuan kpn selesainy...   \n",
       "1  HOREE awal saldo nol Setelah cek jt gue tarik ...   \n",
       "2                               Bankerot nih namanya   \n",
       "3   Alhandulillah Rek Mandiri   amaann       kemarin   \n",
       "4  mohon infonya kapan mandiri   normal lagi urus...   \n",
       "\n",
       "                                        Case Folding  \\\n",
       "0  bagaimana ini gk ada pemberitahuan kpn selesai...   \n",
       "1  horee awal saldo nol setelah cek jt gue tarik ...   \n",
       "2                               bankerot nih namanya   \n",
       "3  alhandulillah rek mandiri saya amaann masih se...   \n",
       "4  mohon infonya kapan mandiri bisa normal lagi u...   \n",
       "\n",
       "                                         normalisasi  \\\n",
       "0  bagaimana ini tidak ada pemberitahuan kapan se...   \n",
       "1  hore awal saldo nol setelah cek juta saya tari...   \n",
       "2                               bangkrut ini namanya   \n",
       "3  alhamdulillah rekening mandiri saya aman masih...   \n",
       "4  mohon infonya kapan mandiri bisa normal lagi u...   \n",
       "\n",
       "                                            Stopword  \\\n",
       "0  bagaimana ini tidak ada pemberitahuan kapan se...   \n",
       "1  hore awal saldo nol setelah cek juta saya tari...   \n",
       "2                               bangkrut ini namanya   \n",
       "3  alhamdulillah rekening mandiri saya aman masih...   \n",
       "4  mohon infonya kapan mandiri bisa normal lagi u...   \n",
       "\n",
       "                                            Stemming  \\\n",
       "0  bagaimana ini tidak ada pemberitahuan kapan se...   \n",
       "1  hore awal saldo nol telah cek juta saya tarik ...   \n",
       "2                                  bangkrut ini nama   \n",
       "3  alhamdulillah rekening mandiri saya aman masih...   \n",
       "4  mohon info kapan mandiri bisa normal lagi urus...   \n",
       "\n",
       "                                          tokenizing  \n",
       "0  ['bagaimana', 'ini', 'tidak', 'ada', 'pemberit...  \n",
       "1  ['hore', 'awal', 'saldo', 'nol', 'telah', 'cek...  \n",
       "2                        ['bangkrut', 'ini', 'nama']  \n",
       "3  ['alhamdulillah', 'rekening', 'mandiri', 'saya...  \n",
       "4  ['mohon', 'info', 'kapan', 'mandiri', 'bisa', ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4fd14a7-5e7d-4e21-8e1a-256bc62dcaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtf = dtf.drop(columns=['Text', 'Text Clean', 'meaningless', 'Case Folding', 'normalisasi', 'Stopword', 'tokenizing'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f82f1488-92fe-4855-ab6e-644f3e2aaf9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Date</th>\n",
       "      <th>Stemming</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-07-20</td>\n",
       "      <td>bagaimana ini tidak ada pemberitahuan kapan se...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-07-20</td>\n",
       "      <td>hore awal saldo nol telah cek juta saya tarik ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-07-20</td>\n",
       "      <td>bangkrut ini nama</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2019-07-20</td>\n",
       "      <td>alhamdulillah rekening mandiri saya aman masih...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2019-07-20</td>\n",
       "      <td>mohon info kapan mandiri bisa normal lagi urus...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id        Date                                           Stemming  Label\n",
       "0   0  2019-07-20  bagaimana ini tidak ada pemberitahuan kapan se...     -1\n",
       "1   1  2019-07-20  hore awal saldo nol telah cek juta saya tarik ...      0\n",
       "2   2  2019-07-20                                  bangkrut ini nama     -1\n",
       "3   3  2019-07-20  alhamdulillah rekening mandiri saya aman masih...      1\n",
       "4   4  2019-07-20  mohon info kapan mandiri bisa normal lagi urus...      0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtf['id'] = dtf.index\n",
    "dtf = dtf.reindex(['id','Date','Stemming','Label'], axis=1)\n",
    "dtf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4947307f-a584-4cf6-bd7e-a75879374f28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    7827\n",
       " 1    6974\n",
       " 0    5724\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtf['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7cabbea0-2556-427c-b915-6ec83428c4ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "167"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cekDup = dtf.duplicated(subset = 'Stemming')\n",
    "cekDup.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5da68525-c223-45fa-aa0c-9c1b4c8c70f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtf.drop_duplicates(subset='Stemming', inplace = True)\n",
    "dtf.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f28eee9-437c-4368-9e95-46855ff7e800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cekDup = dtf.duplicated(subset = 'Stemming')\n",
    "cekDup.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5086fb7c-88b8-4e3a-a1e8-877ead04d9ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id          0\n",
       "Date        0\n",
       "Stemming    1\n",
       "Label       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtf.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "292fdba4-a9ed-431b-8fc0-aff3312edb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtf.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ef087be-5687-4c34-85c3-ebc839d15f15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id          0\n",
       "Date        0\n",
       "Stemming    0\n",
       "Label       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtf.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba776f88-5eab-46c1-b5a5-908d29f78ed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    7769\n",
       " 1    6940\n",
       " 0    5648\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtf['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fc3705-6abd-4465-add8-062e8e6adae7",
   "metadata": {},
   "source": [
    "## split using library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eaa9e61f-3728-47eb-99e9-db323dd3d5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a81199d-b7a1-40c0-b076-ba3b22b1d5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(dtf['Stemming'], dtf['Label'], test_size=0.10, shuffle = True, random_state=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfddc3a2-0318-4715-81c5-d6001664dbf7",
   "metadata": {},
   "source": [
    "# FITUR EKSTRAKSI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da889fa-b314-4697-99fb-67f007ec6fa7",
   "metadata": {},
   "source": [
    "## TF-IDF (UNIGRAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ae84a7a-6421-4c75-806d-3e83029e543d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mencoba tanpa max feature\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,1), max_features = 7000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28cf6e9d-3a08-4433-af97-a178a2f3c073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_tfidf = vectorizer.fit_transform(dtf['Stemming'].astype(str))\n",
    "\n",
    "x_train_tfidf = vectorizer.fit_transform(x_train.astype(str))\n",
    "x_test_tfidf = vectorizer.transform(x_test.astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "03a9942d-fe8c-430f-a073-83f3d75f1925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18321, 7000)\n",
      "(2036, 7000)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_tfidf.shape)\n",
    "print(x_test_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3820a81a-3c0f-4945-a72e-d82ccc36e0e3",
   "metadata": {},
   "source": [
    "# MODELLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9774890f-df87-4a28-a617-0b75a073f23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membuat Model Logistic Regression\n",
    "logreg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59eca4f-6d6e-4611-8d4d-8978bcea2084",
   "metadata": {},
   "source": [
    "## Baseline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e4393d76-777b-4b4e-8eee-5c8d2bc558ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline\n",
    "baseline_params = {\"penalty\" : ['l2'],\n",
    "                   \"dual\" : [False], \n",
    "                   \"tol\" : [0.0001], \n",
    "                   \"C\" : [1.0], \n",
    "                   \"fit_intercept\" : [True], \n",
    "                   \"intercept_scaling\" : [1], \n",
    "                   \"class_weight\" : [None], \n",
    "                   \"random_state\" : [None], \n",
    "                   \"solver\" : ['lbfgs'], \n",
    "                   \"max_iter\" : [10000], \n",
    "                   \"multi_class\" : ['auto'], \n",
    "                   \"verbose\" : [0], \n",
    "                   \"warm_start\" : [False], \n",
    "                   \"n_jobs\" : [None], \n",
    "                   \"l1_ratio\" : [None]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6ff4feb7-d0fa-4335-b7ff-63e39613f333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END C=1.0, class_weight=None, dual=False, fit_intercept=True, intercept_scaling=1, l1_ratio=None, max_iter=10000, multi_class=auto, n_jobs=None, penalty=l2, random_state=None, solver=lbfgs, tol=0.0001, verbose=0, warm_start=False; total time=   1.6s\n",
      "[CV 2/5] END C=1.0, class_weight=None, dual=False, fit_intercept=True, intercept_scaling=1, l1_ratio=None, max_iter=10000, multi_class=auto, n_jobs=None, penalty=l2, random_state=None, solver=lbfgs, tol=0.0001, verbose=0, warm_start=False; total time=   1.8s\n",
      "[CV 3/5] END C=1.0, class_weight=None, dual=False, fit_intercept=True, intercept_scaling=1, l1_ratio=None, max_iter=10000, multi_class=auto, n_jobs=None, penalty=l2, random_state=None, solver=lbfgs, tol=0.0001, verbose=0, warm_start=False; total time=   1.5s\n",
      "[CV 4/5] END C=1.0, class_weight=None, dual=False, fit_intercept=True, intercept_scaling=1, l1_ratio=None, max_iter=10000, multi_class=auto, n_jobs=None, penalty=l2, random_state=None, solver=lbfgs, tol=0.0001, verbose=0, warm_start=False; total time=   1.4s\n",
      "[CV 5/5] END C=1.0, class_weight=None, dual=False, fit_intercept=True, intercept_scaling=1, l1_ratio=None, max_iter=10000, multi_class=auto, n_jobs=None, penalty=l2, random_state=None, solver=lbfgs, tol=0.0001, verbose=0, warm_start=False; total time=   1.3s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(),\n",
       "             param_grid={'C': [1.0], 'class_weight': [None], 'dual': [False],\n",
       "                         'fit_intercept': [True], 'intercept_scaling': [1],\n",
       "                         'l1_ratio': [None], 'max_iter': [10000],\n",
       "                         'multi_class': ['auto'], 'n_jobs': [None],\n",
       "                         'penalty': ['l2'], 'random_state': [None],\n",
       "                         'solver': ['lbfgs'], 'tol': [0.0001], 'verbose': [0],\n",
       "                         'warm_start': [False]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline Model GridSearch\n",
    "baseline_clf = GridSearchCV(logreg, baseline_params, cv=5, refit = True, verbose = 3)\n",
    "baseline_clf.fit(x_train_tfidf,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bdf82126-e4de-43ff-aceb-f686e8d8ced7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.72      0.82      0.77       764\n",
      "           0       0.62      0.54      0.58       602\n",
      "           1       0.79      0.75      0.77       670\n",
      "\n",
      "    accuracy                           0.72      2036\n",
      "   macro avg       0.71      0.71      0.71      2036\n",
      "weighted avg       0.71      0.72      0.71      2036\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict Baseline\n",
    "y_predi_baseline = baseline_clf.predict(x_test_tfidf)\n",
    "print(classification_report(y_test, y_predi_baseline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2e4269a1-ed11-49c8-b472-e6c5278dd782",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7161100196463654"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_predi_baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329801cc-97a4-4804-8b69-b865d59d2aee",
   "metadata": {},
   "source": [
    "## Parameter Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9d9dc88e-6d54-4702-9ccb-111dfdf3be16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#izn\n",
    "# solver = ['sag','saga']\n",
    "# penalty = ['none','l2']\n",
    "# multi_class = ['multinomial','ovr']\n",
    "# C = [1,2,5]\n",
    "\n",
    "#tes\n",
    "solver = ['saga']\n",
    "penalty = ['l2']\n",
    "multi_class = ['ovr']\n",
    "C = [1]\n",
    "\n",
    "\n",
    "# C = [0.1, 1, 10]\n",
    "# penalty = ['l1', 'l2']\n",
    "# penalty = ['l2']\n",
    "# C = np.logspace(-4,4,20)\n",
    "# C = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "# penalty = ['l2','none']\n",
    "# C = [0.1, 1, 2, 5]\n",
    "# solver = ['saga']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8f42dbfd-c51b-4788-8a35-b9f5ec52b07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import to dictionary\n",
    "hyperparameters = dict(C = C,  multi_class = multi_class, penalty = penalty, solver = solver, max_iter = [10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8354d1d5-2c4e-429a-9122-663cbe888f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Memasukan ke Grid Search\n",
    "#CV itu Cross Validation\n",
    "#Menggunakan 10-Fold CV\n",
    "tuned_clf = GridSearchCV(logreg, hyperparameters, cv=5, refit = True, verbose = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9a188927-6adc-41b0-a146-6b8113431dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END C=1, max_iter=10000, multi_class=ovr, penalty=l2, solver=saga; total time=   0.3s\n",
      "[CV 2/5] END C=1, max_iter=10000, multi_class=ovr, penalty=l2, solver=saga; total time=   0.3s\n",
      "[CV 3/5] END C=1, max_iter=10000, multi_class=ovr, penalty=l2, solver=saga; total time=   0.3s\n",
      "[CV 4/5] END C=1, max_iter=10000, multi_class=ovr, penalty=l2, solver=saga; total time=   0.2s\n",
      "[CV 5/5] END C=1, max_iter=10000, multi_class=ovr, penalty=l2, solver=saga; total time=   0.2s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(),\n",
       "             param_grid={'C': [1], 'max_iter': [10000], 'multi_class': ['ovr'],\n",
       "                         'penalty': ['l2'], 'solver': ['saga']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting Model\n",
    "tuned_clf.fit(x_train_tfidf,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e10f767e-a387-4e1f-9997-26c2c920b7c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Penalty: l2\n",
      "Best C: 1\n",
      "Best Solver: saga\n",
      "Best Multi Class: ovr\n"
     ]
    }
   ],
   "source": [
    "#Nilai hyperparameters terbaik\n",
    "print('Best Penalty:', tuned_clf.best_estimator_.get_params()['penalty'])\n",
    "print('Best C:', tuned_clf.best_estimator_.get_params()['C'])\n",
    "print('Best Solver:', tuned_clf.best_estimator_.get_params()['solver'])\n",
    "print('Best Multi Class:', tuned_clf.best_estimator_.get_params()['multi_class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8fbc8414-56e4-4b62-b62e-9dae88f39150",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediksi menggunakan model baru\n",
    "y_predi_tuned = tuned_clf.predict(x_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6085e606-a0e7-44ef-9848-8f80767a2c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.71      0.84      0.77       764\n",
      "           0       0.63      0.52      0.57       602\n",
      "           1       0.79      0.75      0.77       670\n",
      "\n",
      "    accuracy                           0.72      2036\n",
      "   macro avg       0.71      0.71      0.71      2036\n",
      "weighted avg       0.71      0.72      0.71      2036\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_predi_tuned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3dcbe652-e3d9-4ff2-a492-b8996db41dd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7175834970530451"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_predi_tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3702d546-6ca4-4f6b-b485-604ba70cf2e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
